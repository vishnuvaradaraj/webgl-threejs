<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
  "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>
Audio Visualizer
</title>

<script src="beatdetektor.js"></script>

<!-- Our javascript code -->
<script type="text/javascript">

const NUM_SAMPLES = 2048;

function output(str) {
    console.log(str);
}

// Events
// init() once the page has finished loading.
window.onload = init;

var context;
var source;
var analyser;
var jsProcessor;
var buffer;
var audioBuffer;

var ftimer = 0;
var bd = new BeatDetektor(75, 149);
var vu = new BeatDetektor.modules.vis.VU();
var portion = 0;

function init() {

    initAudio();
}

function loadAudioBuffer(url) {
    
    // Load asynchronously
    var request = new XMLHttpRequest();
    request.open("GET", url, true);
    request.responseType = "arraybuffer";

    request.onload = function() {
        audioBuffer = context.createBuffer(request.response, false /*true*/ );
        finishLoad(); // add in the slider, etc. now that we've loaded the audio
    }

    request.send();
}

var processAudio = function(e) {

    // Get left channel input. No need for output arrays. They're hooked up
    // directly to the destination, and we're not doing any processing.
    var inputArrayL = e.inputBuffer.getChannelData(0);

    var freqByteData = new Uint8Array(analyser.frequencyBinCount);

    analyser.getByteFrequencyData(freqByteData);
    //analyser_.fftSize = 2048;
    bd.process(context.currentTime, inputArrayL);
    ftimer += bd.last_update;
    if (ftimer > 1.0 / 24.0) {
        vu.process(bd, ftimer);
        ftimer = 0;
    }

    if (vu.vu_levels.length) {
        var z = vu.vu_levels[0];

        if (context.currentTime > 10.5) {
            console.log(z);
        }

        if (source.gain.value >= 3) {
            console.log(z);
        }
    }

};

function initAudio() {
    context = new webkitAudioContext();

    source = context.createBufferSource();
    analyser = context.createAnalyser();
    analyser.fftSize = NUM_SAMPLES;
    analyser.smoothingTimeConstant = 0.95;

    jsProcessor = context.createJavaScriptNode(NUM_SAMPLES /*bufferSize*/ , 1 /*num inputs*/ , 1 /*num outputs*/ );
    jsProcessor.onaudioprocess = processAudio;


    // Connect audio processing graph
    source.connect(analyser);


    analyser.connect(jsProcessor);
    jsProcessor.connect(context.destination);

    analyser.connect(context.destination);


    loadAudioBuffer("IO-5.0.mp3");
}

function finishLoad() {
    source.buffer = audioBuffer;
    source.loop = true;

    source.noteOn(0.0);
}


</script>

</head>

<body>
</body>
</html>
